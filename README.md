# TrapDoc: Deceiving LLM Users by Injecting Imperceptible Phantom Tokens into Documents

by Hyundong Jin, Sicheol Sung, Shinwoo Park, SeungYeop Baik and Yo-Sub Han

![Main Image](./figures/main.png)

## Abstract

> The reasoning, writing, text-editing, and retrieval capabilities of
> proprietary large language models (LLMs) have advanced rapidly, providing
> users with an ever-expanding set of functionalities. However, this growing
> utility has also led to a serious societal concern: the over-reliance on
> LLMs. In particular, users increasingly delegate tasks such as homework,
> assignments, or the processing of sensitive documents to LLMs without
> meaningful engagement. This form of over-reliance and misuse is emerging as a
> significant social issue. In order to mitigate these issues, we propose a
> method injecting imperceptible phantom tokens into documents, which causes
> LLMs to generate outputs that appear plausible to users but are in fact
> incorrect. Based on this technique, we introduce TrapDoc, a framework
> designed to deceive over-reliant LLM users. Through empirical evaluation, we
> demonstrate the effectiveness of our framework on proprietary LLMs, comparing
> its impact against several baselines. TrapDoc serves as a strong foundation
> for promoting more responsible and thoughtful engagement with language
> models. Our code is available at [our public
> repository](https://github.com/jindong22/TrapDoc).

## Links

- [Paper](https://arxiv.org/abs/2506.00089)

## Citation

```
@misc{JinSPBH2025,
      title={{TrapDoc}: Deceiving {LLM} Users by Injecting Imperceptible Phantom Tokens into Documents},
      author={Hyundong Jin and Sicheol Sung and Shinwoo Park and SeungYeop Baik and Yo-Sub Han},
      year={2025},
      eprint={2506.00089},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2506.00089},
}
```
